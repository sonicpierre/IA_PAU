{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d53d8694",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\saida\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\saida\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "from os import path\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "#import xgboost as xgb\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "nltk.download('wordnet') \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#from imblearn.over_sampling import ADASYN, SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, roc_curve, balanced_accuracy_score\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score, classification_report, confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bc9ebe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset_opencv.csv', delimiter=';', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51a17eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MOBIL EXPLORATION NORWAY INC. WELL 33/9-16 RFT RESULTS DEPTH (mRKB) | HYDSTAT. FM PRESSURE MUD (HP GAUGE) PRESSURE psia 30th-31st DEC 92 RUN 2A 1 2684.4 | 2684.4 38.881 GOOD PERMEABILITY 2685.0 | 2685.0 PLUGGING 2685.0 | 2685.0 i 38.887 GOOD PERMEABILITY 2686.4 | 2686.4 38.903 GOOD PERMEABILITY 2687.0 | 2687.0 . 38.908 GOOD PERMEABILITY 2688.0 | 2688.0 38.919 . GOOD PERMEABILITY 2689.0 | 2689.0 38.930 A GOOD PERMEABILITY 2690.0 | 2690.0 38.941 4 GOOD PERMEABILITY 2693.5 § 2693.5 38.975 \\\\ GOOD PERMEABILITY 2698.5 | 2698.5 39.021 \\\\ GOOD PERMEABILITY 2704.9 | 2704.9 39.077 ie GOOD PERMEABILITY 2713.0 | 2713.0 39.161 5 GOOD PERMEABILITY 2725.0 | 2725.0 39.278 \\\\ GOOD PERMEABILITY 2730.0 | 2730.0 39.335 s GCOD PERMEABILITY 2736.0 | 2736.0 39.494 \\\\. POOR PERMEABILITY 2747.5 | 2747.5 39.492 . GOOD PERMEABILITY 2815.5 § 2815.5 36.468 . GOOD PERMEABILITY 2817.0 | 2817.0 36.477 . GOOD PERMEABILITY 2820.5 § 2820.5 36.509 \\\\< GOOD PERMEABILITY 2823.0 § 2823.0 36.537 fi GOOD PERMEABILITY 2830.0 § 2830.0 36.619 5 GOOD PERMEABILITY 2839.0 | 2839.0 36.687 5 GOOD PERMEABILITY 2845.0 § 2845.0 36.742 5 GOOD PERMEABILITY 2849.0 | 2849.0 36.776 . GOOD PERMEABILITY 2857.0 § 2857.0 37.236 GOOD PERMEABILITY 2863.0 | 2863.0 38.104 i GOOD PERMEABILITY 2685.0 | 2685.0 38.878 GOOD PERMEABILITY - Segregated Sample. oon oO nn & WN NY NY NY DD Bw we te we et sat on O89 O AN OO UG PF OND |= CO @ Figure 2.13 5836.3 5838.0 5837.8 5840.9 5841.6 5843.4 5846.1 5847.9 5853.9 5863.5 5875.9 5898.1 5920.2 5930.9 5943.1 5976.1 6113.3 6116.7 6123.7 6128.5 6142.4 6160.7 6173.7 6182.0 6199.1 6211.0 5833.6 5836.3 5838.0 5837.8 5840.9 5841.6 5843.4 5846.1 5847.9 5853.9 5863.5 5875.9 5898.1 5920.2 5930.9 5943.1 5976.1 6113.3 6116.7 6123.7 6128.5 6142.4 6160.7 6173.7 6182.0 6199.1 6211.0 5833.6 RUN 2A rn nertn © Ke © OD o 4 rc a NN rr o pd z re wo - o - nt = oe pod a = So N r nN N N oo N zs N 26 27 GOOD PERMEABILITY PLUGGING GOOD PERMEABILITY GOOD PERMEABILITY GOOD PERMEABILITY GOOD PERMEABILITY GOOD PERMEABILITY GOOD PERMEABILITY GOOD PERMEABILITY GOOD PERMEABILITY GOOD PERMEABILITY GOOD PERMEABILITY GOOD PERMEABILITY GCOD PERMEABILITY POOR PERMEABILITY GOOD PERMEABILITY GOOD PERMEABILITY GOOD PERMEABILITY GOOD PERMEABILITY GOOD PERMEABILITY GOOD PERMEABILITY GOOD PERMEABILITY GOOD PERMEABILITY GOOD PERMEABILITY GOOD PERMEABILITY GOOD PERMEABILITY GOOD PERMEABILITY - Segregated Sample. oon oO nn & WN a yu = Oo 13 NNN DD Be we we ee on O O AN OO A 5639.2 5640.1 5642.4 3643.1 5644.8 5646.3 3647.9 3652.8 5659.5 5667.7 3679.9 3696.8 5705.0 5728.1 5727.8 5289.2 5290.6 5295.2 5299.3 5311.1 5321.0 5329.0 5333.9 5400.7 5526.5 5638.9 '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "934daee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "975e1a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining pre-processing hyperparameters\n",
    "max_len = 50 \n",
    "trunc_type = \"post\" \n",
    "padding_type = \"post\" \n",
    "oov_tok = \"<OOV>\" \n",
    "vocab_size = 500\n",
    "def text_preprocessing(pdf_text):\n",
    "    tokenizer = Tokenizer(num_words = vocab_size, char_level=False, oov_token = oov_tok)\n",
    "    tokenizer.fit_on_texts(pdf_text)\n",
    "    word_index = tokenizer.word_index\n",
    "    tot_words = len(word_index)\n",
    "    # After Tokenization we will Sequence and padd on training and testing \n",
    "    training_sequences = tokenizer.texts_to_sequences(pdf_text)\n",
    "    training_padded = pad_sequences (training_sequences, maxlen = max_len, padding = padding_type, truncating = trunc_type )\n",
    "    return training_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "99433874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 62ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.036074076"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "reconstructed_model = keras.models.load_model(\"BiLSTM.h5\")\n",
    "\n",
    "input_test = \"wael\"\n",
    "input_model = text_preprocessing(input_test)\n",
    "pred = reconstructed_model.predict(input_model)\n",
    "pred.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec906c09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
